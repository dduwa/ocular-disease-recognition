{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('dataset/csvs/test_df.csv')\n",
    "def file_exists(file_paths):\n",
    "    # Filter out non-existing files\n",
    "    return [file_path for file_path in file_paths if os.path.exists(file_path)]\n",
    "\n",
    "def load_and_prepare_dataset(df, images_dir, shuffle=True, batch_size=32):\n",
    "    images_left = images_dir + df['Left-Fundus']\n",
    "    images_right = images_dir + df['Right-Fundus']\n",
    "\n",
    "    labels_left = df['target'].values\n",
    "    labels_right = df['target'].values\n",
    "\n",
    "    # Combine the left and right images and labels\n",
    "    filenames = np.concatenate([images_left, images_right])\n",
    "    labels = np.concatenate([labels_left, labels_right])\n",
    "\n",
    "    # Filter out filenames that do not exist\n",
    "    valid_filenames = file_exists(filenames)\n",
    "    valid_labels = labels[np.isin(filenames, valid_filenames)]  # Keep labels corresponding to the valid filenames\n",
    "\n",
    "    # Creating TensorFlow dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((valid_filenames, valid_labels))\n",
    "    dataset = dataset.map(parse_image_and_label)  # Apply the preprocessing function\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(valid_filenames))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "def parse_image_and_label(image_path, label_string):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    label = tf.strings.substr(label_string, 1, tf.strings.length(label_string) - 2)\n",
    "    label = tf.strings.to_number(tf.strings.split(label, ','), out_type=tf.float32)\n",
    "    return image, label\n",
    "test_ds = load_and_prepare_dataset(test_df, 'dataset/preprocessed_images/', shuffle=False, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(model, test_ds\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: x), algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpermutation\u001b[39m\u001b[38;5;124m'\u001b[39m, max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m8\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Compute SHAP values (this might take some time depending on the size of test_ds)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer(\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mX\u001b[49m[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m], max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, outputs\u001b[38;5;241m=\u001b[39mshap\u001b[38;5;241m.\u001b[39mExplanation\u001b[38;5;241m.\u001b[39margsort\u001b[38;5;241m.\u001b[39mflip[:\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Summary plot\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Ensure class_labels is a list of class names in the order your model outputs them\u001b[39;00m\n\u001b[0;32m     21\u001b[0m shap\u001b[38;5;241m.\u001b[39msummary_plot(shap_values)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "# Load the model (assuming load_model is defined or imported from a library like keras)\n",
    "model = load_model('best_model_Resnet50.h5')\n",
    "\n",
    "# Given the image shape is 224x224x3, you directly use these dimensions for the masker\n",
    "#masker = shap.maskers.Image(\"inpaint_telea\", 224, 224)\n",
    "\n",
    "\n",
    "\n",
    "explainer = shap.Explainer(model, test_ds.map(lambda x, y: x), algorithm='permutation', max_evals=2 * 8 + 1)\n",
    "\n",
    "# Compute SHAP values (this might take some time depending on the size of test_ds)\n",
    "shap_values = explainer(\n",
    "    , max_evals=500, batch_size=32, outputs=shap.Explanation.argsort.flip[:1]\n",
    ")\n",
    "# Summary plot\n",
    "# Ensure class_labels is a list of class names in the order your model outputs them\n",
    "shap.summary_plot(shap_values)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tf)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
